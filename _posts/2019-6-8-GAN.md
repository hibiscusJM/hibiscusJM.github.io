---
title: GAN-迷惑问题1
tags: GAN
renderNumberedHeading: true
grammar_cjkRuby: true
---


前言：最近在看生成对抗网络的相关论文，对于原论文作者回答的GAN不能用于离散数据一直很迷惑，其他改进论文中也都提到了这一点，为了更好的理解，把这一点吃透很重要....
**Question: GAN不能用于离散数据，离散数据到底指什么?**
		GAN最初用于图像领域，通过生成器生成假样本迷惑判别器，经过博弈对抗的思想用来生成适应该模型的数据，其中关于GAN的基本原理相关的博客有很多，这里就不再具体介绍了，本文主要解释GAN面对离散数据时的困境...
		GAN的作者在原版论文中提到GAN只适用于连续型数据的生成，对于离散型数据效果不佳，因此在NLP领域一直无法超越生成模型的另一种模型——VAE。文本类型的数据是最典型的离散型数据，而这里的离散并不是指：*文本由一个词一个词生成*。
		首先连续型数据很好理解：最典型的就是图像数据了，图像数据在使用时被表示为矩阵，而图像数据中的元素是可微分的，它的数值直接反映出图像本身的明暗色彩等因素，从图像矩阵到图像，不需要**“采样**”，改变其中某个元素值就可以直接反映在图像上，比如我们经常用到的调色板，我们任意滑动一下，图像便有所变化，也证实了图像数据连续可微。
		而文本数据在使用时，通常用one-hot向量表示，在预测下一个单词时通常需要得到一个one-hot向量，然后从词库中找到该单词，而使用分类器或其他神经网络通常得到一个K维的概率分布（K是单词的个数），然后再将该概率分布过渡到one-hot再去查出对应的单词，实际上这个过程就是“Sampling”。而面对这种数据，判别数据无法将梯度直接反向传播给生成网络，因为基于梯度的优化方法通常是微调网络中的参数，然后看输出结果是否变好，而离散数据在参数微调后，即使概率分布的结果优化了一点，但**过渡到one-hot向量时通常没有变化，也就是采样并没有发生变化**，这样一来判别器给出的评价就没有意义，生成器的训练也会失去方向。
		而如果直接将优化后的概率分布结果给到判别器，这样做也会有很大的问题，因为真实样本是one-hot向量，判别器很容易区分，不用判断生成分布与真实分布是否更加接近，只需要识别出浮点数就可以了。
		当然有问题就会有解决办法，已经有相关论文提出了解决该问题的方法，最早是通过引入了强化学习中的policy gradient，这种方法需要较大的计算资源，并且需要较长的学习周期，所以后来又提出WGAN，这篇论文几乎达到了原版GAN的高度。后续会详细讲解这种方法!